# 🔍 Adaptation follow human attention: Gaze-assisted medical segment anything model

A PyTorch implementation of **main_GAM**, we present the Gaze-assisted medical segment Anything Model (GAM), which pioneers a human-guided and highly efficient SAM adaptation framework and integrates the adaptation process into clinical workflows for the first time.This repository includes training and testing scripts for reproducible experiments.

---

## 📌 Highlights

- 🧠 **GAM Module**: Introduces a lightweight yet effective attention mechanism that separately models spatial and channel-wise features, then fuses them via a dual-branch architecture.
- ⚙️ **Plug-and-Play**: Can be seamlessly integrated into existing CNN backbones like ResNet.
- 🚀 **Performance Boost**: Demonstrated improved classification accuracy across multiple datasets with minimal computational overhead.

---

## 📁 Project Structure


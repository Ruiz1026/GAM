# ğŸ” Adaptation follow human attention: Gaze-assisted medical segment anything model

A PyTorch implementation of **main_GAM**, we present the Gaze-assisted medical segment Anything Model (GAM), which pioneers a human-guided and highly efficient SAM adaptation framework and integrates the adaptation process into clinical workflows for the first time.This repository includes training and testing scripts for reproducible experiments.

---

## ğŸ“Œ Highlights

- ğŸ§  **GAM Module**: Introduces a lightweight yet effective attention mechanism that separately models spatial and channel-wise features, then fuses them via a dual-branch architecture.
- âš™ï¸ **Plug-and-Play**: Can be seamlessly integrated into existing CNN backbones like ResNet.
- ğŸš€ **Performance Boost**: Demonstrated improved classification accuracy across multiple datasets with minimal computational overhead.

---

## ğŸ“ Project Structure

